<!-- 
    imbalance.html
    Webpage for papers within the imbalance data category
    It has a Classification and Regression section

    Author: Josias Moukpe
    Advisor: Dr. Chan
    Date: 6/14/2023

 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Data Imbalanced Papers</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>


  <style>
    body {
      font-family: 'Roboto', sans-serif;
      background: linear-gradient(45deg, #8B0000, #FF4500);
      background-size: 200% 200%;
      animation: Gradient 3s ease infinite;
      color: #333;
    }

    @keyframes Gradient {
      0% {
        background-position: 0% 50%
      }

      50% {
        background-position: 100% 50%
      }

      100% {
        background-position: 0% 50%
      }
    }

    .root-container {
      margin: 2em auto;
      max-width: 90%;
      padding: 1em 2em;
      box-sizing: border-box;
      background-color: #fff;
      border-radius: 8px;
      /* box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); */
    }

    h2 {
      color: #444;
      margin-bottom: 1em;
    }

    .paper-container {
      margin-bottom: 2em;
    }

    .paper-title {
      color: #8B0000;
    }

    a {
      color: #007BFF;
      text-decoration: none;
      font-style: italic;
      overflow-wrap: break-word;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
  <!-- <link rel="stylesheet" href="css/style.css">
        <link rel="stylesheet" href="css/imbalance.css"> -->

</head>

<body>
  <div class="root-container">
    <a href="https://cs.fit.edu/~pkc/r/readingList.html">https://cs.fit.edu/~pkc/r/readingList.html</a>
    <h2>Pertinent Machine Learning Papers</h2>
    <div class="papers-group">
      <ol>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Policy Adaptation via Language Optimization: Decomposing Tasks for Few-Shot
              Imitation</h3>

            <p>
              <strong>BibTex</strong>
              <br>
              @inproceedings{myers2024palo, <br>
              title={Policy Adaptation via Language Optimization: Decomposing Tasks for Few-Shot Imitation}, <br>
              author={Myers, Vivek and Zheng, Chunyuan and Mees, Oier and Fang, Kuan and Levine, Sergey}, <br>
              booktitle={8th Annual Conference on Robot Learning} <br>
              year={2024}} <br>

            </p>

            url=<a href="https://arxiv.org/pdf/2408.16228">https://arxiv.org/pdf/2408.16228</a><br>

            <strong>Summary</strong>
            <br>
            <p>
              The method proposed, Policy Adaptation via Language Optimization (PALO), aims to enable few-shot
              adaptation of pre-trained language-conditioned robot policies to new, unseen tasks. The key insight is to
              leverage vision-language models (VLMs) to decompose high-level instructions into smaller, more manageable
              subtasks, which the robot can execute using its existing knowledge. This approach circumvents the need for
              extensive fine-tuning on new tasks, which is often infeasible due to the high cost of collecting
              large-scale teleoperated demonstrations. Instead, PALO relies on the semantic understanding provided by
              VLMs to propose candidate decompositions of the task, using a small set of demonstrations as a calibration
              set to guide this decomposition process. The method then optimizes over these decompositions and selects
              the one that minimizes validation error on the given demonstrations.

              The core of the approach involves task decomposition through language. Given a high-level task
              instruction, the VLM generates a set of candidate decompositions that break the task into sequential
              subtasks. These subtasks are designed to align with the robot's prior training, leveraging its existing
              capabilities. Each candidate decomposition is evaluated to find the optimal one that can guide the robot
              to successfully complete the task. The evaluation process involves rolling out the pre-trained policy on
              the candidate decompositions and computing the cost based on the mean squared error between the robot's
              predicted actions and the actions demonstrated by the expert. By minimizing this error, PALO identifies
              the sequence of language subtasks that most effectively bridges the robot's prior knowledge with the new
              task requirements.

              An important aspect of PALO is the consideration of when to transition between subtasks. The method
              introduces an additional variable to represent the time steps allocated to each subtask, recognizing that
              the execution of each subtask may vary depending on the initial state and the environment's stochasticity.
              This variable is optimized alongside the task decomposition to ensure the robot executes the sequence of
              subtasks in a manner that fits the dynamics of the specific task instance. This joint optimization of
              subtasks and their timing is critical for adapting to long-horizon, multi-step tasks that require a
              precise and fluid combination of actions.

              PALO operates under two key assumptions: first, that the low-level subtasks required for the new task are
              present within the robot's prior training, and second, that the VLM can generate decompositions that are
              consistent with the semantics of the task in the given environment. These assumptions are essential for
              the method's success, as they ensure that the robot can use its pre-trained policy to execute the proposed
              subtasks effectively. By optimizing within the language space rather than directly fine-tuning policy
              parameters, PALO enables rapid adaptation with significantly fewer demonstrations, making it a
              sample-efficient approach to handling a variety of complex, unseen robotic manipulation tasks. They also
              found that
              hierarchical decomposition to subtasks as high level and low level subtasks help further improve
              performance. This paper shows that learning generalizable low level skills and knowning how to break down
              high level OoD instructions into low level InD skills helps.
            </p>

            <p>
              <strong>Problem</strong>
              Improving robot adaptability to new tasks with minimal demonstrations by leveraging vision-language models
              to semantically decompose complex instructions into executable subtasks.
            </p>
            <strong>Images</strong><br>
            <div class="row">
              <div class="col">
                <img src="../../images/ml/palo-fig1.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                <img src="../../images/ml/palo-fig2.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                <img src="../../images/ml/palo-fig3.png" class="img-fluid rounded" alt="...">
              </div>
            </div>
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Concept Learning with Energy-Based Models</h3>

            <p>
              <strong>BibTex</strong>
              <br>
              @article{mordatch2018concept, <br>
              title={Concept learning with energy-based models}, <br>
              author={Mordatch, Igor}, <br>
              journal={arXiv preprint arXiv:1811.02486}, <br>
              year={2018}}<br>
            </p>

            url=<a href="https://arxiv.org/pdf/1811.02486">https://arxiv.org/pdf/1811.02486</a><br>

            <strong>Summary</strong>
            <br>
            <p>
              This paper presents a framework that uses Energy-Based Models (EBMs) to learn, identify, and generate
              abstract concepts from events in an environment. The core idea is that each concept is represented by an
              energy function, which takes a state trajectory (the sequence of entity behaviors over time), an
              attention mask (focusing on relevant entities in the event), and a concept code (parameters
              representing the concept) as inputs. The energy function returns a scalar energy value that indicates
              how well the given event configuration aligns with the specified concept. Low energy means the event
              satisfies the concept, while high energy signals a mismatch.

              The approach leverages inference-time optimization, which occurs dynamically during task execution
              rather than relying on pre-trained, fixed models. By minimizing the energy during inference, the model can
              either generate new events that fit the concept or identify existing events that match it. This method is
              more flexible than traditional learning approaches, as it adapts to new situations on the fly by adjusting
              the event parameters in real-time.

              The technique operates within a meta-learning framework, where the model generalizes its learning
              across tasks and environments. Once the energy function is trained, it can be reused in different contexts
              without retraining. This makes it particularly effective for tasks requiring few-shot learning, where
              the model needs to generalize from just a few examples. By observing a small set of demonstration events,
              the model predicts future states and identifies key entities through attention. This is formulated as a
              maximum likelihood estimation problem to maximize the probability of the observed states given the
              concept.

              The framework also employs a relational network architecture in the energy function, enabling it to
              model interactions between multiple entities, such as spatial or temporal relationships. This allows the
              model to understand and generate complex multi-entity dynamics, such as objects being "inside" or moving
              "slowly."

              To improve sampling during inference, the model uses a KL-divergence objective that refines the
              sampling process. This objective minimizes the difference between the biased sampling distribution (due to
              the truncated inference steps) and the true distribution of real-world events. This ensures that the
              generated samples during inference are realistic and align closely with the learned concepts.

              Finally, the model supports concept transfer across environments. Once a concept is learned, it can be
              transferred and applied in new environments, such as transferring concepts learned in a 2D environment to
              a 3D robot simulation. This is achieved by manually mapping representations between environments and using
              the learned energy function as a cost function in the new environment’s optimization process.

              In summary, the framework combines energy-based modeling, inference-time optimization, relational
              networks, few-shot learning, KL-divergence sampling refinement, and cross-environment concept transfer.
              These techniques enable the model to generalize from limited demonstrations, handle complex multi-entity
              concepts, and adapt to new tasks and environments, all while efficiently identifying or generating events
              that fit learned abstract concepts.
            </p>

            <p>
              <strong>Problem</strong>
              The problem being solved is learning abstract concepts from a few demonstrations and being able to
              generate or identify similar concepts in new events using energy-based models​
            </p>

            <strong>Images</strong><br>
            <div class="row">
              <div class="col">
                <img src="../../images/ml/emb-fig1.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                <img src="../../images/ml/emb-fig2.png" class="img-fluid rounded" alt="...">
              </div>
            </div>
            <div class="row">
              <div class="col">
                <img src="../../images/ml/emb-fig3.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                <img src="../../images/ml/emb-fig4.png" class="img-fluid rounded" alt="...">
              </div>
            </div>
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">"Why Should I Trust You?" Explaining the Predictions of Any Classifier</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">A Unified Approach to Interpreting Model Predictions</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Axiomatic attribution for deep networks</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Towards better understanding of gradient-based attribution methods for Deep Neural
              Networks </h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation
              Methods</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Do Feature Attribution Methods Correctly Attribute Features?</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">mixup: Beyond Empirical Risk Minimization</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Manifold Mixup: Better Representations by Interpolating Hidden States</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
               <div class="col">
                   <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
               </div>
               <div class="col">
                   <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
               </div>
           </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Revisiting Deep Learning Models for Tabular Data</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
              <div class="col">
                  <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                  <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
              </div>
          </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in
              Deep
              Learning</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
              <div class="col">
                  <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                  <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
              </div>
          </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Robustness via cross-domain ensembles</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
              <div class="col">
                  <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                  <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
              </div>
          </div> -->
          </div>
        </li>
        <li>
          <div class="paper-container">
            <h3 class="paper-title">Online Knowledge Distillation via Collaborative Learning</h3>

            <p>
              <strong>BibTex</strong>
              <br>

            </p>

            url=<a href=""></a><br>

            <strong>Summary</strong>
            <br>
            <p>

            </p>

            <p>
              <strong>Problem</strong>

            </p>

            <strong>Images</strong><br>
            <!-- <div class="row">
              <div class="col">
                  <img src="../../images/ml/saint-fig1.png" class="img-fluid rounded" alt="...">
              </div>
              <div class="col">
                  <img src="../../images/ml/saint-fig2.png" class="img-fluid rounded" alt="...">
              </div>
          </div> -->
          </div>
        </li>
      </ol>
    </div>
  </div>
</body>

</html>