<!-- 
    imbalance.html
    Webpage for papers within the imbalance data category
    It has a Classification and Regression section

    Author: Josias Moukpe
    Advisor: Dr. Chan
    Date: 6/14/2023

 -->
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Data Imbalanced Papers</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>



    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background: linear-gradient(45deg, #8B0000, #FF4500);
            background-size: 200% 200%;
            animation: Gradient 3s ease infinite;
            color: #333;
        }

        @keyframes Gradient {
            0% {
                background-position: 0% 50%
            }

            50% {
                background-position: 100% 50%
            }

            100% {
                background-position: 0% 50%
            }
        }

        .root-container {
            margin: 2em auto;
            max-width: 90%;
            padding: 1em 2em;
            box-sizing: border-box;
            background-color: #fff;
            border-radius: 8px;
            /* box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); */
        }

        h2 {
            color: #444;
            margin-bottom: 1em;
        }

        .paper-container {
            margin-bottom: 2em;
        }

        .paper-title {
            color: #8B0000;
        }

        a {
            color: #007BFF;
            text-decoration: none;
            font-style: italic;
        }

        a:hover {
            text-decoration: underline;
        }
    </style>
    <!-- <link rel="stylesheet" href="css/style.css">
         <link rel="stylesheet" href="css/imbalance.css"> -->

</head>

<body>
    <div class="root-container">
        <a href="https://cs.fit.edu/~pkc/r/readingList.html">https://cs.fit.edu/~pkc/r/readingList.html</a>
        <h2>Representation Learning</h2>
        <div class="papers-group">
            <ol>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title"> Momentum contrast for unsupervised visual representation learning</h3>
                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{he2020moco, <br>
                            title={Momentum contrast for unsupervised visual representation learning}, <br>
                            author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross}, <br>
                            booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, <br>
                            year={2020}} <br>
                            
                        </p>
                        url=<a
                            href="https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdfl">
                            https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf</a><br>
                        <strong>Summary</strong>
                        <br>
                        <p>
                           

                </p>
                <p>
                    <strong>Problem</strong>
                
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>

                    </ul>
                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/decoupling-fig1.png" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/decoupling-fig2.png" class="img-fluid rounded" alt="...">
                    </div>

                </div>
        </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title"> A simple framework for contrastive learning of visual representations</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{chen2020simclr, <br>
                    title={A simple framework for contrastive learning of visual representations}, <br>
                    author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey}, <br>
                    booktitle={International conference on machine learning}, <br>
                    year={2020}}  <br>
                </p>
                url=<a
                    href=http://proceedings.mlr.press/v119/chen20j/chen20j.pdf"> http://proceedings.mlr.press/v119/chen20j/chen20j.pdf</a><br>
                <strong>Summary</strong>
                <br>
                <p>
                    
                </p>

                <p>
                    <strong>Problem</strong>
                    
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong><br>
                    
                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/bbn-fig1.png" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/bbn-fig2.png" class="img-fluid rounded" alt="...">
                    </div>

                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Bootstrap your own latent-a new approach to self-supervised learning</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @article{grill2020byol, <br>
                    title={Bootstrap your own latent-a new approach to self-supervised learning}, <br>
                    author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others}, <br>
                    journal={Advances in neural information processing systems}, <br>
                    year={2020}} <br>
                </p>

                url=<a
                    href="https://proceedings.neurips.cc/paper_files/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf">
                    https://proceedings.neurips.cc/paper_files/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf</a><br>
                <strong>Summary</strong>
                <br>
                <p>
                    

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>
            

                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/meta-softmax-fig1.png" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/meta-softmax-fig2.png" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Self-supervised relational reasoning for representation learning</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @article{patacchiola2020relational, <br>
                    title={Self-supervised relational reasoning for representation learning}, <br>
                    author={Patacchiola, Massimiliano and Storkey, Amos J}, <br>
                    journal={Advances in Neural Information Processing Systems}, <br>
                    year={2020}} <br>
                </p>
                url=<a
                    href="https://proceedings.neurips.cc/paper_files/paper/2020/file/29539ed932d32f1c56324cded92c07c2-Paper.pdf">
                    https://proceedings.neurips.cc/paper_files/paper/2020/file/29539ed932d32f1c56324cded92c07c2-Paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>
                    
                </p>

                <p>
                    <strong>Problem</strong>
                    
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>

                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/kcl-fig1.png" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/kcl-fig2.png" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Long-tail learning via logit adjustment</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    menon2021logitadjustment, <br>
                    title={Long-tail learning via logit adjustment}, <br>
                    author={Menon, Aditya Krishna and Jayasumana, Sadeep and Rawat, Ankit Singh and Jain, Himanshu and
                    Veit, Andreas and Kumar, Sanjiv}, <br>
                    booktitle={International Conference on Learning Representations}, <br>
                    year={2021}}
                </p>
                url=<a href="https://openreview.net/pdf?id=37nvvqkCo5">https://openreview.net/pdf?id=37nvvqkCo5</a><br>
                <strong>Summary</strong>
                <br>
                <p>
                    The authors propose a framework to generalize on the logit adjustment methods. They observed that
                    previous methods focused on scaling the logits and assumed the target distribution is uniform.
                    They propose a logit adjustment framework that can be implemented post hoc to any existing model
                    where an adjustment term based on the prior distribution of the target dataset is added to the
                    logits.
                    It can also be implemented as a loss function. The loss function would be adjusted based on added
                    terms that would take into account the known prior of the
                    target dataset. The authors showed that their method indeed was a general formulation of previous
                    methods and that it outperformed previous methods on benchmark datasets.
                </p>

                <p>
                    <strong>Problem</strong>
                    logits are not balanced for long-tail data distributions, majority classes have larger logits than
                    minority classes. furthermore, previous
                    attempts at adjusting logits focus on scaling the logits and assumed the target distribution is
                    uniform
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>
                    a logit adjustment framework that can be implemented post hoc to any existing model where an
                    adjustment term based on the prior distribution
                    of the target dataset is added to the logits. It can also be implemented as a loss function.


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/logitadj-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/logitadj-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Long-tailed Recognition by Routing Diverse Distribution-Aware Experts</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    wang2020ride, <br>
                    title={Long-tailed Recognition by Routing Diverse Distribution-Aware Experts}, <br>
                    author={Wang, Xudong and Lian, Long and Miao, Zhongqi and Liu, Ziwei and Yu, Stella}, <br>
                    booktitle={International Conference on Learning Representations}, <br>
                    year={2020}}
                </p>
                url=<a
                    href="https://openreview.net/pdf?id=D9I3drBz4UC">https://openreview.net/pdf?id=D9I3drBz4UC</a><br>

                <strong>Summary</strong>
                <br>
                <p>

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/ride-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/ride-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification
                </h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    wang2021hybridsc, <br>
                    title={Contrastive learning based hybrid networks for long-tailed image classification}, <br>
                    author={Wang, Peng and Han, Kai and Wei, Xiu-Shen and Zhang, Lei and Wang, Lei}, <br>
                    booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, <br>
                    year={2021}}
                </p>

                url=<a
                    href=https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Contrastive_Learning_Based_Hybrid_Networks_for_Long-Tailed_Image_Classification_CVPR_2021_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Contrastive_Learning_Based_Hybrid_Networks_for_Long-Tailed_Image_Classification_CVPR_2021_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/hybridsc-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/hybridsc-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Disentangling Label Distribution for Long-tailed Visual Recognition</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    hong2021disentangling, <br>
                    title={Disentangling label distribution for long-tailed visual recognition}, <br>
                    author={Hong, Youngkyu and Han, Seungju and Choi, Kwanghee and Seo, Seokjun and Kim, Beomsu and
                    Chang, Buru}, <br>
                    booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, <br>
                    year={2021}}
                </p>
                url=<a
                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/lade-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/lade-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Distribution Alignment: A Unified Framework for Long-tail Visual Recognition
                </h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    zhang2021disalign, <br>
                    title={Distribution alignment: A unified framework for long-tail visual recognition}, <br>
                    author={Zhang, Songyang and Li, Zeming and Yan, Shipeng and He, Xuming and Sun, Jian}, <br>
                    booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, <br>
                    year={2021}}
                </p>
                url=<a
                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Distribution_Alignment_A_Unified_Framework_for_Long-Tail_Visual_Recognition_CVPR_2021_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Distribution_Alignment_A_Unified_Framework_for_Long-Tail_Visual_Recognition_CVPR_2021_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/disalign-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/disalign-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Improving Calibration for Long-Tailed Recognition</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    zhong2021mislas, <br>
                    title={Improving calibration for long-tailed recognition}, <br>
                    author={Zhong, Zhisheng and Cui, Jiequan and Liu, Shu and Jia, Jiaya}, <br>
                    booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, <br>
                    year={2021}}
                </p>

                url=<a
                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Improving_Calibration_for_Long-Tailed_Recognition_CVPR_2021_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Improving_Calibration_for_Long-Tailed_Recognition_CVPR_2021_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/mislas-fig1.PNG" class="img-fluid rounded" alt="...">

                    </div>
                    <div class="col">

                        <img src="../../images/repr/mislas-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">RSG: A Simple but Effective Module for Learning Imbalanced Datasets</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    wang2021rsg, <br>
                    title={Rsg: A simple but effective module for learning imbalanced datasets}, <br>
                    author={Wang, Jianfeng and Lukasiewicz, Thomas and Hu, Xiaolin and Cai, Jianfei and Xu, Zhenghua},
                    <br>
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, <br>
                    year={2021}}
                </p>

                url=<a
                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_RSG_A_Simple_but_Effective_Module_for_Learning_Imbalanced_Datasets_CVPR_2021_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_RSG_A_Simple_but_Effective_Module_for_Learning_Imbalanced_Datasets_CVPR_2021_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>
                    In this paper, the authors propose a simple but effective module called RSG to address the long-tail
                    problem. RSG works by
                    generating new samples for the rare classes. RSG uses variation information among the real samples
                    from the frequent classes to
                    generate new samples for the rare classes. RSG is composed of 3 modules:
                <ol>
                    <li>Center estimation module: to find class feature centers</li>
                    <li>Contrastive module: to check if 2 feature maps are from the same class</li>
                    <li>Vector Transformation module: generate new rare samples with displacement vectors</li>
                </ol>
                The center estimation module and the contrastive module are both trained using a a center estimation
                with sample contrastive loss
                and the vector transformation module is trained using a maximized vector loss. Injected between layers
                of a CNN, RSG takes the feature
                maps from the previous layer and outputs new synthetic samples for the rare classes. The center
                estimation module estimates takes the feature
                maps and estimate a set of centers in each clas which can be used a anchor for obtaining feature
                displacement of each sample. It is implemented
                as a linear model. The contrastive module ensures that no frequent-class-relevent information is present
                in the feature displacement. It is implemented
                with a CNN that will output a probability distribution of yes/no that 2 feature maps belong to the same
                class. The vector transformation module
                calculates the feature displacement of each frequent-class sample based on estimated centers and use the
                displacement to generate
                new samples for the rare classes. First a displacement vector is calculated for each sample by
                subtracting the sample's feature map from its closest
                upsampled center. Then the displacement vector is transformed by a convolutional layer to produce a
                displacement vector that will be applied the rare-class
                sample as opposed to the center to push away the decision boundary, thus enlarging the feature space.
                The transformed vector is optimized by a maximized vector loss
                to be collinear with the rare-class displacement vector to its center. the loss function is a linear
                combination of the center estimation with sample contrastive loss
                , the maximized vector loss and the classification loss.

                </p>
                <p>
                    <strong>Problem</strong>
                    Current methods on long-tail recognition lacks good generalization because they are not trained end
                    to end, and
                    variation information used to produce new synthetic data sample are not class-irrelevent.
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>
                <ol>
                    <li>Rare-class sample generator which can be trained end to end</li>
                    <li>Assuming class samples follow a multinomial distribution so there can be center(s) for each
                        class</li>
                    <li>Feature displacement indicates the displacement of a sample to its corresponding center in a
                        class and should not contain class-relevent information</li>
                    <li>Adding feature displacement vector to rare-class samples instead of centers to improve the
                        decision boundary</li>
                    <li>Transformed freq class displacement vector should be collinear to rare-class displacement vector
                        of the sample to be applied to</li>
                </ol>
                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/rsg-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/rsg-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Balanced Contrastive Learning for Long-Tailed Visual Recognition</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{
                    zhu2022bcl, <br>
                    title={Balanced contrastive learning for long-tailed visual recognition}, <br>
                    author={Zhu, Jianggang and Wang, Zheng and Chen, Jingjing and Chen, Yi-Ping Phoebe and Jiang,
                    Yu-Gang}, <br>
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, <br>
                    year={2022}}
                </p>

                url=<a
                    href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>
                    In this paper, the authors investigate the geomtric structure formed by representation vectors of
                    classes and the class prototypes.
                    They observed that past methods fail to form regular simplex geometries in the feature space, which
                    is crucial for the generalization of the learned representations.
                    A regular simplex geometry is has 3 crucial characteristics
                <ol>
                    <li>the mean of all class prototypes should be the origin of the representation space</li>
                    <li>the class prototypes should be at a radius distance from the origin</li>
                    <li>the class prototypes should be vectors of which the dot product with one another can be
                        calculated</li>
                </ol>
                Most methods fail to satisfy the 1st characteristic, which means that the mean of all class prototypes
                is not the origin and therefore the class
                prototypes are not at equal distance from each other. To addres this the propose a 2 branch learning
                framework, where one branch is
                used to learn a feature extractor and a classifier called the classification branch. The other branch is
                used
                for contrastive learning called the contrastive learning branch. The classification branch employs
                cross-entropy loss and logit adjustment based on the
                class prior. The contrastive learning branch employs a novel loss called balanced contrastive loss (BCL)
                aiming to produce a regular simplex geometry in the feature space.
                The BCL loss is composed of 2 parts, a class averaging part and a class component part. During
                experimentation, the authors observed that
                when trained on imbalance data, regular Supervised Contrastive Learning (SCL), using the available
                expamples for each classes, grows the
                gradients for head classes far more than the tail classes. This is because the head classes have more
                examples than the tail classes. To alleviate that
                class averaging works by averaging the instances of each class in a minibach so that each class has the
                same approximate contribution to the optimization.
                The class component part, which carries the bulk of the positive results obtained, consists of
                introducing a class prototype for each class in all the minibatches.
                This allows all classes to be represented in all minibatches and therefore all classes contribute to the
                optimization stably. The class prototypes here are obtained
                from the MLP projection of the class specific weights of the linear classifier in the classification
                branch. The whole system is trained end-to-end.

                </p>
                <p>
                    <strong>Problem</strong>
                    Current approaches to long-tailed visual recognition (LTVR) fail to form regular simplex geometries
                    in the feature space, which is crucial for the generalization of the learned representations.
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>
                <ol>
                    <li>balanced feature space has a regular simplex geometry</li>
                    <li>class averaging reduces the effect head classes dominating the gradients in optimization</li>
                    <li>class component introduces class prototypes in all minibatches so that all classes contribute to
                        the optimization stably</li>
                    <li>logit adjustment for classifier logits using the imbalanced class priors</li>
                    <li>class prototypes are obtained from the MLP projection of the class specific weights of the
                        linear classifier in the classification branch</li>
                </ol>
                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/bcl-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/bcl-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="paper-container">
                <h3 class="paper-title">Long-Tailed Recognition via Weight Balancing</h3>

                <p>
                    <strong>BibTex</strong>
                    <br>
                    @inproceedings{alshammari2022weightbal, <br>
                    title={Long-tailed recognition via weight balancing}, <br>
                    author={Alshammari, Shaden and Wang, Yu-Xiong and Ramanan, Deva and Kong, Shu}, <br>
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, <br>
                    year={2022}} <br>
                </p>

                url=<a
                    href="https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf">
                    https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf</a><br>

                <strong>Summary</strong>
                <br>
                <p>

                </p>

                <p>
                    <strong>Problem</strong>
                </p>
                <p>
                    <strong>Solution, Ideas and Why</strong>


                </p>

                <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/weightbal-fig1.PNG" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/weightbal-fig2.PNG" class="img-fluid rounded" alt="...">
                    </div>
                </div>
            </div>
        </li>

        </ol>
    </div>
    </div>
</body>

</html>