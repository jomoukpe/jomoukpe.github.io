<!-- 
    imbalance.html
    Webpage for papers within the imbalance data category
    It has a Classification and Regression section

    Author: Josias Moukpe
    Advisor: Dr. Chan
    Date: 6/14/2023

 -->
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Data Imbalanced Papers</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>



    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background: linear-gradient(45deg, #8B0000, #FF4500);
            background-size: 200% 200%;
            animation: Gradient 3s ease infinite;
            color: #333;
        }

        @keyframes Gradient {
            0% {
                background-position: 0% 50%
            }

            50% {
                background-position: 100% 50%
            }

            100% {
                background-position: 0% 50%
            }
        }

        .root-container {
            margin: 2em auto;
            max-width: 90%;
            padding: 1em 2em;
            box-sizing: border-box;
            background-color: #fff;
            border-radius: 8px;
            /* box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); */
        }

        h2 {
            color: #444;
            margin-bottom: 1em;
        }

        .paper-container {
            margin-bottom: 2em;
        }

        .paper-title {
            color: #8B0000;
        }

        a {
            color: #007BFF;
            text-decoration: none;
            font-style: italic;
        }

        a:hover {
            text-decoration: underline;
        }
    </style>
    <!-- <link rel="stylesheet" href="css/style.css">
         <link rel="stylesheet" href="css/imbalance.css"> -->

</head>

<body>
    <div class="root-container">
        <a href="https://cs.fit.edu/~pkc/r/readingList.html">https://cs.fit.edu/~pkc/r/readingList.html</a>
        <h2>Representation Learning</h2>
        <div class="papers-group">
            <ol>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title"> Momentum contrast for unsupervised visual representation learning</h3>
                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{he2020moco, <br>
                            title={Momentum contrast for unsupervised visual representation learning}, <br>
                            author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross}, <br>
                            booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern
                            recognition}, <br>
                            year={2020}} <br>

                        </p>
                        url=<a
                            href="https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf">
                            https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf</a><br>
                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper is tackling the problem of representation learning with contrastive loss where an
                            encoded query is matched to dictionary of encoded keys.
                            Contrastive methods are sensitive to the number of negative examples, usually limited by the
                            batch. Compared to previous methods such as
                            end-to-end training of 2 encoders or using a memory bank, this paper proposes a new method
                            called Momentum Contrast (MoCo) that uses a queue to store
                            multiples batches of encoded keys in Fifo style and a momentum update for the key encoder to
                            ensure all encoded keys in the queue belong to the same representation space.
                            The queue overcome the limitated on the end to end technique which was limited by the
                            overall hardware memory available for the batch and the momementum update
                            ensure that the keys are in the same representation space unlike the keys in the memory
                            bank. From training, only the query encoder is updated by backpropagation. The
                            key encoder is conservatively updated by momementum update where at most 10% of the key
                            encoder is updated by the query encoder. They notice Batch normalization is not
                            effective in this case because it leaks information via intra-batch communication across
                            samples. To fix that, they introduce Shuffling Batch Normalization where they use
                            multiple GPUs, performing batch normalization on independly for each GPU and then shuffling
                            the samples across GPUs.

                        </p>
                        <p>
                            <strong>Problem</strong>
                            representation learning by expand negative pairs
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            Fifo queue of multiple batches of previously encoded keys. the queue is larger than any
                            single batch.
                            Momentum update for the key encoder to ensure all encoded keys in the queue belong to the
                            same representation space.
                            </ul>
                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/moco-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/moco-fig2.png" class="img-fluid rounded" alt="...">
                            </div>

                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title"> A simple framework for contrastive learning of visual representations
                        </h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{chen2020simclr, <br>
                            title={A simple framework for contrastive learning of visual representations}, <br>
                            author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey}, <br>
                            booktitle={International conference on machine learning}, <br>
                            year={2020}} <br>
                        </p>
                        url=<a href="http://proceedings.mlr.press/v119/chen20j/chen20j.pdf">
                            http://proceedings.mlr.press/v119/chen20j/chen20j.pdf</a><br>
                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper tackles the problem of representation learning with contrastive loss. The paper
                            proposes a simple framework called SimCLR that uses a
                            non-linear projection head on top of the encoder to get an embedding that is contrasted with
                            other embedding of the same sample. Given a sample, they apply
                            a random composition of augmentations like crop, color etc to get a positive pair of
                            augmented view from the same sample and contrast it with
                            negative pairs of view from different samples in the batch. As such, the perform the best,
                            the number of negative examples needs to be large, making
                            the batch size large. They explored different combinations of augmentations and found that
                            the best combination is a composition of random crop, color distortion, sobel filtering and
                            gaussian blur.
                            The introduced projection head as simple mlp before the contrastive loss to put distance
                            between features and output so less information is lost in features.
                            Overall, they found that introducing a simclr stage before finetuning the model on the
                            downstream task improves the performance of the model.
                        </p>

                        <p>
                            <strong>Problem</strong>
                            representation learning by expand negative pairs through data augmentation
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong><br>
                            Composition of augmentations like crop, color etc to get a positive pair of augmented view
                            from the same sample. Contrast with negative pairs of view from different samples
                            Add a projector (mlp) on top of the repr. encoder to get embeddings that will be contrasted.
                            Puts distance between features and output so less information is lost in features.
                            pretrain -> simclr -> finetuning
                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/simclr-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/simclr-fig2.png" class="img-fluid rounded" alt="...">
                            </div>

                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Bootstrap your own latent-a new approach to self-supervised learning
                        </h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @article{grill2020byol, <br>
                            title={Bootstrap your own latent-a new approach to self-supervised learning}, <br>
                            author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin
                            and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and
                            Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others}, <br>
                            journal={Advances in neural information processing systems}, <br>
                            year={2020}} <br>
                        </p>

                        url=<a
                            href="https://proceedings.neurips.cc/paper_files/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf">
                            https://proceedings.neurips.cc/paper_files/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf</a><br>
                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper tackles the problem of representation learning but with no negative pairs. The
                            paper proposes a framework called Bootstrap Your Own Latent (BYOL) that uses 2 branches a
                            momentum encoder,
                            a projector head, a predictor head, and no negative pairs. BYOL works by 2 augmented views
                            of the same sample, and passing to the 2 branches. The first branch has an online encoder
                            updated by backpropagation
                            that produces a representation of the augmented view. That representation is passed to the
                            projector head which is a mlp that outputs a projection of the representation. Finally the
                            projection is passed to the predictor head
                            which is a mlp that outputs a prediction of the projection of the other branch. The other
                            branch has a target encoder updated by momentum update that produces a representation of the
                            other augmented view. The representation
                            is passed to the projector head to get a projection of the representation. That second
                            projection is the projection that the predictor head is trying to predict. The momentum
                            update is a at most 10% update of the online encoder.
                            BYOL uses symmetric loss, meaning that the augmented views are passed to both branches in
                            the first order then the reverse order. This approach is at risk of collapsing to a constant
                            function where all inputs are mapped to the same
                            representation. To avoid that, they use the momentum update on the target encoder branch.


                        </p>

                        <p>
                            <strong>Problem</strong>
                            representation learning with no negative pairs
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            positive pair into 2 branches, one with encoder, projector, and a predictor learning to
                            predict the projection of the other branch, encouraging same representation for positive
                            pair.
                            momentum update on the target network branch (no predictor) to avoid collapse of the network
                            to a constant function give same representation for all inputs.
                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/byol-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/byol-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Self-supervised relational reasoning for representation learning</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @article{patacchiola2020relational, <br>
                            title={Self-supervised relational reasoning for representation learning}, <br>
                            author={Patacchiola, Massimiliano and Storkey, Amos J}, <br>
                            journal={Advances in Neural Information Processing Systems}, <br>
                            year={2020}} <br>
                        </p>
                        url=<a
                            href="https://proceedings.neurips.cc/paper_files/paper/2020/file/29539ed932d32f1c56324cded92c07c2-Paper.pdf">
                            https://proceedings.neurips.cc/paper_files/paper/2020/file/29539ed932d32f1c56324cded92c07c2-Paper.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper tackles the problem of representation learning but with relational reasoning
                            module and cross entropy loss instead of using contrastive loss. They propose a framework
                            called Relational reasoning that uses a relational network
                            to ingest concatenated positive pair from augmented view of the same sample and negative
                            pair from augmented views of different samples. The relational network outputs relation
                            probablity of a pair being related to the same sample.
                            The relational network is trained with binary cross entropy loss. They explored different
                            aggregation methods for the relational network and found that concatenation is the best.
                        </p>

                        <p>
                            <strong>Problem</strong>
                            representation learning with 1 positive pair and 1 negative pair
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            relational network ingest concatenated positive pair and negative pair. outputs relation
                            probablity (1 for related, 0 otherwise).
                            more efficient as the number of comparision scales linearly with the batch size (instead of
                            quadratically), best aggregation is concatenation, loss is focal loss.
                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/relational-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/relational-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Unsupervised learning of visual features by contrasting cluster
                            assignments</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @article{caron2020swav, <br>
                            title={Unsupervised learning of visual features by contrasting cluster assignments}, <br>
                            author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski,
                            Piotr and Joulin, Armand}, <br>
                            journal={Advances in neural information processing systems}, <br>
                            year={2020}} <br>

                        </p>
                        url=<a
                            href="https://proceedings.neurips.cc/paper_files/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf">
                            https://proceedings.neurips.cc/paper_files/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf</a><br>
                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper tackles the problem of representation learning but with no negative pairs and no
                            contrastive loss. The paper proposes a framework called SwAV that
                            doesn't match projections but matches cluster assignments of augmented views.
                        </p>

                        <p>
                            <strong>Problem</strong>
                            representation learning with no negative pairs
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            matching cluster assingments of positive pairs to learned cluster prototypes (symmetric
                            loss).
                            multi-crop or using 2 standard resolution images and multiple low resolution crops to
                            increase performance.


                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/swav-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/swav-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Vime: Extending the success of self-and semi-supervised learning to
                            tabular domain</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @article{yoon2020vime, <br>
                            title={Vime: Extending the success of self-and semi-supervised learning to tabular domain},
                            <br>
                            author={Yoon, Jinsung and Zhang, Yao and Jordon, James and van der Schaar, Mihaela}, <br>
                            journal={Advances in Neural Information Processing Systems}, <br>
                            year={2020}} <br>
                        </p>
                        url=<a
                            href="https://proceedings.neurips.cc/paper_files/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Paper.pdf">
                            https://proceedings.neurips.cc/paper_files/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Paper.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper is tackling the problem of representation learning with tabular data. The paper
                            propose VIME or Value Imputation and masked estimation
                            where there are a 2 stages, a self supervised stage and a semi-supervised stage. In the self
                            supervised stage, they mask a random subset of features and then
                            pass the corrupted sample to the encoder which then outputs a representation. The
                            representation is then passed to a decoder which outputs a reconstruction of the
                            original sample and another decoder which outputs the mask applied to the samples. The
                            second stage is a semi-supervised stage where they create several corrupted
                            views of the same sample and pass it to the encoder along with the original sample. The
                            encoder outputs a representation for each view. The representations are passed
                            to the predictor head to output predictions for the original samples and the corrupted
                            views. The original sample prediction is compared to the original sample label
                            and the corrupted views are compared with each other to make sure, coming from the same
                            original sample, they are consistent in predictions. In total, the network has
                            3 branches and 4 loss functions. The reconstruction and masked estimation loss for the first
                            stage. The Supervised and Consistency loss for second stage. The masking process
                            is done by randomly shuffling the values of the features (columns) of the samples in the
                            batch.
                        </p>

                        <p>
                            <strong>Problem</strong>
                            representation learning on tabular data
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            mask input samples and learn generative features to predict the original sample and the
                            applied mask.
                            in addition to supervised loss, use consistency loss that encourages same representation for
                            augmeted views of same input

                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/vime-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/vime-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Exploring simple siamese representation learning</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{chen2021simsiam, <br>
                            title={Exploring simple siamese representation learning}, <br>
                            author={Chen, Xinlei and He, Kaiming}, <br>
                            booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern
                            recognition}, <br>
                            year={2021}} <br>
                        </p>

                        url=<a
                            href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.pdf">
                            https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>
                            This paper tackles the problem of representation learning with siamese network and the
                            collapse issue. The propose a simple siamese network that uses predictor branch and a
                            non-predictor branch with stop gradient,
                            no negative pairs, and no momentum encoders. From a single sample, they generate 2 augmented
                            views and pass them to the 2 branches in both this order and the flip order of the views.
                            Both branches have the same encoder, but only the predictive branch
                            has gradient updates. the encoders output representation and on the predictive branch, the
                            representation is passed to a predictor head to predict the representation of the second
                            branch. The loss is a symmetric
                            cosine simimlarity loss between the prediction of the first branch and the projection of the
                            second branch. They show how their approach is similar to an expectation minimization
                            algorithm and the stop-gradient is important
                            to preventing collapse to a constant function.

                        <p>
                            <strong>Problem</strong>
                            representation learning with siamese network simplified to avoid collapse without using
                            negative pairs
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            stop gradient in non-predictor branch to avoid collapse to constant function.
                            symmetric (views are swapped) loss matching first branch prediction and second branch
                            projection.

                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/simsiam-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/simsiam-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Barlow twins: Self-supervised learning via redundancy reduction</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{zbontar2021barlow, <br>
                            title={Barlow twins: Self-supervised learning via redundancy reduction}, <br>
                            author={Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
                            <br>
                            booktitle={International Conference on Machine Learning}, <br>
                            year={2021}} <br>
                        </p>
                        url=<a
                            href="http://proceedings.mlr.press/v139/zbontar21a/zbontar21a.pdf">http://proceedings.mlr.press/v139/zbontar21a/zbontar21a.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p> 
                            This paper tackles the issue of avoid collapse to a constant function in representation learning by measuring the cross correlation matrix. Given a batch of samples, they generate a random 
                            pair of batches of augmented views passed into a shared decoder and projectin head to produce a pair of projections of the batch of input samples. From the batches of projections, they calculate 
                            the cross correlation matrix between the 2 batches of projections. The cross correlation matrix should be an identity matrix meaning that the same feature indices should be correlated and different feature 
                            indices should be non correlated. To calculate the correlation, they assume the features are meaned at 0 over the batch dimension and divide by largest cross correlation value to avoid large feature values
                            being interpreted as large correlation. 
                        </p>

                        <p>
                            <strong>Problem</strong>
                            representation learning without negative pairs and avoiding collapse
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>
                            cross correlation matrix loss between 2 views embeddings should be identity matrix where same features should be correlated and different features should be non correlated.
                            the cross correlation calculations should include a normalization denominator so large feature values are not interpreted as large correlation 

                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/barlow-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/barlow-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Whitening for self-supervised representation learning</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{ermolov2021whitening, <br>
                            title={Whitening for self-supervised representation learning}, <br>
                            author={Ermolov, Aleksandr and Siarohin, Aliaksandr and Sangineto, Enver and Sebe, Nicu},
                            <br>
                            booktitle={International Conference on Machine Learning}, <br>
                            year={2021}} <br>
                        </p>
                        url=<a
                            href="http://proceedings.mlr.press/v139/ermolov21a/ermolov21a.pdf">http://proceedings.mlr.press/v139/ermolov21a/ermolov21a.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>

                        </p>

                        <p>
                            <strong>Problem</strong>
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>


                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/whitening-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/whitening-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Subtab: Subsetting features of tabular data for self-supervised
                            representation learning</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @article{ucar2021subtab, <br>
                            title={Subtab: Subsetting features of tabular data for self-supervised representation
                            learning}, <br>
                            author={Ucar, Talip and Hajiramezanali, Ehsan and Edwards, Lindsay}, <br>
                            journal={Advances in Neural Information Processing Systems}, <br>
                            year={2021}} <br>
                        </p>

                        url=<a
                            href="https://proceedings.neurips.cc/paper/2021/file/9c8661befae6dbcd08304dbf4dcaf0db-Paper.pdf">
                            https://proceedings.neurips.cc/paper/2021/file/9c8661befae6dbcd08304dbf4dcaf0db-Paper.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>

                        </p>

                        <p>
                            <strong>Problem</strong>
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>


                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/subtab-fig1.png" class="img-fluid rounded" alt="...">

                            </div>
                            <div class="col">

                                <img src="../../images/repr/subtab-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Scarf: Self-Supervised Contrastive Learning using Random Feature
                            Corruption</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{bahri2021scarf, <br>
                            title={Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption}, <br>
                            author={Bahri, Dara and Jiang, Heinrich and Tay, Yi and Metzler, Donald}, <br>
                            booktitle={International Conference on Learning Representations}, <br>
                            year={2021}} <br>
                        </p>

                        url=<a href="https://openreview.net/pdf?id=CuV_qYkmKb3">
                            https://openreview.net/pdf?id=CuV_qYkmKb3</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>

                        </p>
                        <p>
                            <strong>Problem</strong>

                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>

                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/scarf-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/scarf-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">Semantic-aware auto-encoders for self-supervised representation learning
                        </h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @inproceedings{wang2022semantic, <br>
                            title={Semantic-aware auto-encoders for self-supervised representation learning}, <br>
                            author={Wang, Guangrun and Tang, Yansong and Lin, Liang and Torr, Philip HS}, <br>
                            booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
                            Recognition}, <br>
                            year={2022}} <br>
                        </p>

                        url=<a
                            href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf">
                            https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>


                        </p>
                        <p>
                            <strong>Problem</strong>

                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>

                        </p>

                        <strong>Images</strong><br>
                        <div class="row">
                            <div class="col">
                                <img src="../../images/repr/semantic-fig1.png" class="img-fluid rounded" alt="...">
                            </div>
                            <div class="col">
                                <img src="../../images/repr/semantic-fig2.png" class="img-fluid rounded" alt="...">
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="paper-container">
                        <h3 class="paper-title">On embeddings for numerical features in tabular deep learning</h3>

                        <p>
                            <strong>BibTex</strong>
                            <br>
                            @article{gorishniy2022embeddings, <br>
                            title={On embeddings for numerical features in tabular deep learning}, <br>
                            author={Gorishniy, Yury and Rubachev, Ivan and Babenko, Artem}, <br>
                            journal={Advances in Neural Information Processing Systems}, <br>
                            year={2022}} <br>

                        </p>

                        url=<a
                            href="https://proceedings.neurips.cc/paper_files/paper/2022/file/9e9f0ffc3d836836ca96cbf8fe14b105-Paper-Conference.pdf">
                            https://proceedings.neurips.cc/paper_files/paper/2022/file/9e9f0ffc3d836836ca96cbf8fe14b105-Paper-Conference.pdf</a><br>

                        <strong>Summary</strong>
                        <br>
                        <p>

                        </p>

                        <p>
                            <strong>Problem</strong>
                        </p>
                        <p>
                            <strong>Solution, Ideas and Why</strong>


                        </p>

                        <!-- <strong>Images</strong><br>
                <div class="row">
                    <div class="col">
                        <img src="../../images/repr/embeddings-fig1.png" class="img-fluid rounded" alt="...">
                    </div>
                    <div class="col">
                        <img src="../../images/repr/embeddings-fig2.png" class="img-fluid rounded" alt="...">
                    </div>
                </div> -->
                    </div>
                </li>

            </ol>
        </div>
    </div>
</body>

</html>